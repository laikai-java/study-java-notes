> 本文由 [简悦 SimpRead](http://ksria.com/simpread/) 转码， 原文地址 [blog.csdn.net](https://blog.csdn.net/java_wxid/article/details/106896221)

首先 HashMap 是 Map 的一个实现类，而 Map 存储形式是键值对 (key,value) 的。可以看成是一个一个的 Entry。Entry 所存放的位置是由 key 来决定的。

Map 中的 key 是无序的且不可重复的，所有的 key 可以看成是一个 set 集合，如果出现 Map 中的 key 如果是自定义类的对象，则必须重写 hashCode 和 equals 方法，因为如果不重写，使用的是 Object 类中的 hashCode 和 equals 方法，比较的是内存地址值不是比内容。

Map 中的 value 是无序的可重复的，所有的 value 可以看成是 Collection 集合，Map 中的 value 如果是自定义类的对象必须重写 equals 方法。

至于要重写 hashCode 和 equals 分别做什么用，拿 hashMap 底层原理来说：

当我们向 HashMap 中存放一个元素 (k1,v1)，先根据 k1 的 hashCode 方法来决定在数组中存放的位置。

如果这个位置没有其它元素，将 (k1,v1) 直接放入 Node 类型的数组中，这个数组初始化容量是 16，默认的加载因子是 0.75，也就是当元素加到 12 的时候，底层会进行扩容，扩容为原来的 2 倍。如果该位置已经有其它元素 (k2,v2)，那就调用 k1 的 equals 方法和 k2 进行比较二个元素是否相同，如果结果为 true，说明二个元素是一样的，用 v1 替换 v2，如果返回值为 false，二个元素不一样，就用链表的形式将 (k1,v1) 存放。

不过当链表中的数据较多时，查询的效率会下降，所以在 JDK1.8 版本后做了一个升级，hashmap 就是当**链表中的元素达到 8** 并且**元素数量大于 64** 时，会将链表替换成红黑树才会树化时，会将链表替换成红黑树，来提高查找效率。因为对于搜索，插入，删除操作多的情况下，使用红黑树的效率要高一些。

原因是因为红黑树是一种特殊的二叉查找树，二叉查找树所有节点的左子树都小于该节点，所有节点的右子树都大于该节点，就可以通过大小比较关系来进行快速的检索。

在红黑树上插入或者删除一个节点之后，红黑树就发生了变化，可能不满足红黑树的 5 条性质，也就不再是一颗红黑树了，而是一颗普通的树，可以通过左旋和右旋，使这颗树重新成为红黑树。怕大家搞混，我把二个树之间的区别给上（红黑树与平衡二叉树的区别？[https://blog.csdn.net/qfc8930858/article/details/89856274](https://blog.csdn.net/qfc8930858/article/details/89856274)）

![](https://img-blog.csdnimg.cn/20200325110151906.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2phdmFfd3hpZA==,size_16,color_FFFFFF,t_70)

而且像这种二叉树结构比较常见的使用场景是 Mysql 二种引擎的索引.

首先 B 树它的每个节点都是 Key.value 的二元组，它的 key 都是从左到右递增的排序，value 中存储数据。这种模式在读取数据方面的性能很高，因为有单独的索引文件，Myisam 的存储文件有三个. frm 是表的结构文件，.MYD 是数据文件，.MYI 是索引文件。不过 Myisam 也有些缺点它只支持表级锁，不支持行级锁也不支持事务，外键等，所以一般用于大数据存储。

![](https://img-blog.csdnimg.cn/20200325110835343.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2phdmFfd3hpZA==,size_16,color_FFFFFF,t_70)

然后是 InnoDB，它的存储文件相比 Myisam 少一个索引文件，它是以 ID 为索引的数据存储，**_数据现在都被存在了叶子结点，索引在非叶结点上。_**而这些节点分散在索引页上。在 InnoDB 里，每个页默认 16KB，假设索引的是 8B 的 long 型数据，每个 key 后有个页号 4B，还有 6B 的其他数据，那么每个页的扇出系数为 16KB/(8B+4B+6B)≈1000，即每个页可以索引 1000 个 key。在高度 h=3 时，s=1000^3=10 亿！！也就是说，InnoDB 通过三次索引页的 I/O，即可索引 10 亿的 key，而非叶节点这一行存储的索引，数量就多了，I/O 的次数就少了。而 Myisam 在每个节点都存储数据和索引，这样就减少了每页存储的索引数量。而且 InnoDB 它还支持行级，表级锁，也支持事务，外键.

![](https://img-blog.csdnimg.cn/20200325110932768.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2phdmFfd3hpZA==,size_16,color_FFFFFF,t_70)

 **另外对于 HashMap 实际使用过程中还是会出现一些线程安全问题**：

**HashMap** 是线程不安全的，在多线程环境下，使用 Hashmap 进行 put 操作会引起死循环，导致 CPU 利用率接近 100%，而且会抛出并发修改异常，导致原因是并发争取线程资源，修改数据导致的，一个线程正在写，一个线程过来争抢，导致线程写的过程被其他线程打断，导致数据不一致。

**HashTable** 是线程安全的，只不过实现代价却太大了，简单粗暴，get/put 所有相关操作都是 synchronized 的，这相当于给整个哈希表加了一把大锁。多线程访问时候，只要有一个线程访问或操作该对象，那其他线程只能阻塞，相当于将所有的操作串行化，在竞争激烈的并发场景中性能就会非常差。

为了应对 hashmap 在并发环境下不安全问题可以使用，**ConcurrentHashMap** 大量的利用了 **volatile，CAS** 等技术来减少锁竞争对于性能的影响。

在 **JDK1.7 版本**中 ConcurrentHashMap 避免了对全局加锁，改成了局部加锁（**分段锁**），分段锁技术，将数据分成一段一段的存储，然后给每一段数据配一把锁，当一个线程占用锁访问其中一个段数据的时候，其他段的数据也能被其他线程访问，能够实现真正的并发访问。不过这种结构的带来的副作用是 Hash 的过程要比普通的 HashMap 要长。

所以在 **JDK1.8 版本**中 CurrentHashMap 内部中的 value 使用 **volatile** 修饰，保证并发的可见性以及禁止指令重排，只不过 volatile 不保证原子性，使用为了确保原子性，采用 **CAS**（比较交换）这种乐观锁来解决。

**CAS 操作包含三个操作数 —— 内存位置（V）、预期原值（A）和新值 (B)。**

如果内存地址里面的值和 A 的值是一样的，那么就将内存里面的值更新成 B。CAS 是通过无限循环来获取数据的，若果在第一轮循环中，a 线程获取地址里面的值被 b 线程修改了，那么 a 线程需要自旋，到下次循环才有可能机会执行。

**volatile 有三个特性：可见性，不保证原子性，禁止指令重排。**

可见性：线程 1 从主内存中拿数据 1 到自己的线程工作空间进行操作（假设是加 1）这个时候数据 1 已经改为数据 2 了，将数据 2 写回主内存时通知其他线程（线程 2，线程 3），主内存中的数据 1 已改为数据 2 了，让其他线程重新拿新的数据（数据 2）。

不保证原子性：线程 1 从主内存中拿了一个值为 1 的数据到自己的工作空间里面进行加 1 的操作，值变为 2，写回主内存，然后还没有来得及通知其他线程，线程 1 就被线程 2 抢占了，CPU 分配，线程 1 被挂起，线程 2 还是拿着原来主内存中的数据值为 1 进行加 1，值变成 2，写回主内存，将主内存值为 2 的替换成 2，这时线程 1 的通知到了，线程 2 重新去主内存拿值为 2 的数据。

禁止指令重排：首先指令重排是程序执行的时候不总是从上往下执行的，就像高考答题，可以先做容易的题目再做难的，这时做题的顺序就不是从上往下了。禁止指令重排就杜绝了这种情况。

（一般面试官开始问你会从 java 基础问起，一问大多数会问到集合这一块，而集合问的较多的是 HashMap，这个时候你就可以往这些方向带着面试官问你，而且扩展的深度也够，所以上面的干货够你说个十来分钟吧，第一个问题拿下后，面试官心里至少简单你的基础够扎实，第一印象分就留下了）